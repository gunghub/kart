{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yv1ph3-AbeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc29019-71fb-4f06-f00d-92c12d9b404a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PySuperTuxKart==1.1.2 in /usr/local/anaconda3/lib/python3.8/site-packages (1.1.2)\r\n",
            "Requirement already satisfied: PySuperTuxKartData in /usr/local/anaconda3/lib/python3.8/site-packages (from PySuperTuxKart==1.1.2) (1.0.0)\r\n",
            "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.8/site-packages (from PySuperTuxKartData->PySuperTuxKart==1.1.2) (2.28.1)\r\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->PySuperTuxKartData->PySuperTuxKart==1.1.2) (1.26.12)\r\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->PySuperTuxKartData->PySuperTuxKart==1.1.2) (2.0.4)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->PySuperTuxKartData->PySuperTuxKart==1.1.2) (2022.9.24)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->PySuperTuxKartData->PySuperTuxKart==1.1.2) (3.4)\n",
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: imageio in /usr/local/anaconda3/lib/python3.8/site-packages (2.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/anaconda3/lib/python3.8/site-packages (from imageio) (9.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.8/site-packages (from imageio) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "# %pip install PySuperTuxKart==1.1.2\n",
        "# # !pip install imageio==2.4.1\n",
        "# !pip install imageio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "_La3IBGwvons"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os._exit(00)"
      ],
      "metadata": {
        "id": "dm0umin5m9TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Environmental flag to visualize in colab.\n",
        "\n",
        "\n",
        "%env ON_COLAB=1\n",
        "from importlib import reload\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import *\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from modules_official import dense_transforms;reload(dense_transforms)\n",
        "from modules_official import controller;reload(controller)\n",
        "from modules_official import planner;reload(planner)\n",
        "from modules_official import train;reload(train)\n",
        "from modules_official import util;reload(util)\n",
        "\n",
        "\n",
        "from modules_jt import control_func_module_jt;reload(control_func_module_jt)\n",
        "from modules_jt import generate_dataset_module_jt;reload(generate_dataset_module_jt)\n",
        "from modules_jt import train_module_jt;reload(train_module_jt)\n",
        "from modules_jt import train_module_jt2;reload(train_module_jt2)\n",
        "from modules_jt import global_variables;reload(global_variables)\n",
        "\n",
        "from adaption_pkg import train_adaption_mod;reload(train_adaption_mod)\n",
        "\n",
        "from modules_team import control_func_module_team\n",
        "\n",
        "\n",
        "\n",
        "if 'pytux_jt' not in locals():\n",
        "    pytux_jt = util.PyTuxJT()\n",
        "\n"
      ],
      "metadata": {
        "id": "cVipfe3GPoZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d973e01-91f0-4c49-c28d-93889239a46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: ON_COLAB=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassifierJT(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    super().__init__()\n",
        "    self.batch_norm=BatchNorm2d(num_features=3)\n",
        "    self.resnet=torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False)\n",
        "\n",
        "    post_resnet=[]\n",
        "    post_resnet.append(ReLU(inplace=True))\n",
        "    post_resnet.append(Linear(in_features=1000,out_features=global_variables.NUM_TRACKS))\n",
        "    self.post_resnet=torch.nn.Sequential(*post_resnet)\n",
        "    \n",
        "  def forward(self, image_batch):# [batch_size,channel_size=3,height=96,width=128]\n",
        "    \"\"\"\n",
        "    Your code here\n",
        "    Predict the aim point in image coordinate, given the supertuxkart image\n",
        "    @img: (B,3,96,128)\n",
        "    return (B,2) \n",
        "    \"\"\"\n",
        "    x = self.batch_norm(image_batch)\n",
        "    x = self.resnet(x)#[batch_size, 1, 6, 8]\n",
        "    x = self.post_resnet(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "def spatial_argmax_jt(logit):\n",
        "    \"\"\"\n",
        "    Compute the soft-argmax of a heatmap\n",
        "    :param logit: A tensor of size BS x H x W\n",
        "    :return: A tensor of size BS x 2 the soft-argmax in normalized coordinates (-1 .. 1)\n",
        "    \"\"\"\n",
        "   \n",
        "   \n",
        "    weights = F.softmax(logit.view(logit.size(0), -1), dim=-1).view_as(logit)\n",
        "    #ok, let's discuss what this just did\n",
        "    # logit.view(logit.size(0), -1) reshapes the input, which is a 1xaxb tensor as \n",
        "    # 1 x ab\n",
        "    #softmax then takes the softmax\n",
        "    #finally, this is converted back to a 1xaxb tensor\n",
        "\n",
        "    #the following code computes the center of mass\n",
        "    #formula in more convenient form is given in slides\n",
        "    # print(weights[0])\n",
        "    # linspace(-1,1)是一個數列，第一個點為-1，最後一個點為 1，一共有 logit.shape[2]個數。類似於找重心。\n",
        "    firstcoord = (weights.sum(1) * torch.linspace(-1, 1, logit.size(2)).to(logit.device)[None]).sum(1)\n",
        "    secondcoord = (weights.sum(2) * torch.linspace(-1, 1, logit.size(1)).to(logit.device)[None]).sum(1)\n",
        "    a = torch.stack((firstcoord, secondcoord), 1)\n",
        "    \n",
        "\n",
        "    return a\n",
        "\n",
        "\n",
        "class PlannerResJT(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "    super().__init__()\n",
        "    self.batch_norm=BatchNorm2d(num_features=3)\n",
        "    self.resnet=torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False)\n",
        "    \n",
        "\n",
        "  def forward(self, image_batch):# [batch_size,channel_size=3,height=96,width=128]\n",
        "    \"\"\"\n",
        "    Your code here\n",
        "    Predict the aim point in image coordinate, given the supertuxkart image\n",
        "    @img: (B,3,96,128)\n",
        "    return (B,2) \n",
        "    \"\"\"\n",
        "    \n",
        "    x = self.batch_norm(image_batch)\n",
        "    x = self.resnet(x)#[batch_size, 1, 6, 8]\n",
        "    x=x.reshape(-1,25,40)\n",
        "    # print(x.shape)\n",
        "\n",
        "    return spatial_argmax_jt(x) #輸入是[batch_size,height=6,width=8],輸出是[batch_size,2]"
      ],
      "metadata": {
        "id": "EY-lrQ7DqPJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### M3"
      ],
      "metadata": {
        "id": "V3RlZU2io8Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier=train_module_jt.load_planner_jt(\"classifier_res_jt1_v3.th\", ClassifierJT)\n",
        "classifier.eval()\n",
        "\n",
        "class AdaptedPlannerM3JT(torch.nn.Module):\n",
        "  def __init__(self,device=\"cuda:0\"):\n",
        "    super().__init__()\n",
        "\n",
        "    self.device=device\n",
        "    self.batch_norm=BatchNorm2d(num_features=3)\n",
        "    self.resnet=torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False)\n",
        "    \n",
        "\n",
        "    self.adapters=ModuleList()\n",
        "    for track_code in range(global_variables.NUM_TRACKS):\n",
        "      \n",
        "      ll6=[]\n",
        "      ll=ll6\n",
        "      \n",
        "      ll.append(Linear(in_features=1000,out_features=1024))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "      ll.append(Linear(1024,2048))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "      ll.append(Linear(2048,1024))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "      ll.append(Linear(1024,512))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "      ll.append(Linear(512,256))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "      ll.append(Linear(256,128))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "      ll.append(Linear(128,40))\n",
        "      adapter=torch.nn.Sequential(*ll6)\n",
        "      self.adapters.append(adapter)\n",
        "\n",
        "  def forward(self, image_batch, code_batch=None,device=None):# [batch_size,channel_size=3,height=96,width=128]\n",
        "    \n",
        "    if device is None:\n",
        "      device=self.device\n",
        "\n",
        "    if code_batch is None:\n",
        "      classifier.to(device)\n",
        "      classifier.eval()\n",
        "      code_batch=classifier(image_batch).argmax(1)\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    x = self.batch_norm(image_batch)\n",
        "    x = self.resnet(x)#[batch_size, 1000]\n",
        "\n",
        "\n",
        "    batch_size=len(image_batch)\n",
        "    num_tracks=global_variables.NUM_TRACKS\n",
        "    width=40\n",
        "    height=25\n",
        "    \n",
        "\n",
        "\n",
        "    indices_list=[[] for i in range(num_tracks)]\n",
        "    for index in range(batch_size):\n",
        "      indices_list[code_batch[index].item()].append(index) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    mini_map_batches=[]\n",
        "    for i in range(num_tracks):\n",
        "      mini_map_batches.append(x.index_select(0,torch.tensor(indices_list[i], dtype=torch.int32).to(device)))\n",
        "    \n",
        "\n",
        "    weights_batch=[1]*batch_size\n",
        "    for i in range(num_tracks):\n",
        "\n",
        "      mini_map_batch=mini_map_batches[i]\n",
        "      mini_map_batch.to(device)\n",
        "\n",
        "      if len(mini_map_batch)==0:\n",
        "        continue\n",
        "\n",
        "      z=self.adapters[i](mini_map_batch) # batch_size, 40\n",
        "      z=F.softmax(z, dim=1)\n",
        "\n",
        "\n",
        "      for j in range(len(mini_map_batch)):\n",
        "        weights_batch[indices_list[i][j]]=z[j]\n",
        "    \n",
        "    weights_batch=torch.stack(weights_batch).to(device) # batchsize, 1, 40\n",
        "    x=x.reshape(-1,25,40)\n",
        "\n",
        "    x=x*weights_batch.unsqueeze(1)\n",
        "\n",
        "\n",
        "  \n",
        "    return spatial_argmax_jt(x)\n",
        "\n",
        "\n",
        "# adapted_planner_m2=AdaptedPlannerM2JT(device=\"cpu\")\n",
        "# print(adapted_planner_m2)\n",
        "# output=adapted_planner_m2(image_batch.to(\"cpu\"),code_batch=code_batch.to(\"cpu\"),device=\"cpu\")\n",
        "# print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MP_YSakQo6r4",
        "outputId": "521b1fc3-7e5f-4589-ea3e-67fcc81413cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "/usr/local/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "1ZjvpXfYLvP9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train model"
      ],
      "metadata": {
        "id": "XqYqWS9kQC0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args_jt=train_module_jt2.TrainArgsJT2()\n",
        "args_jt.num_workers=2\n",
        "args_jt.random_seed=99998\n",
        "tracks = [\n",
        "    'lighthouse', \n",
        "    'zengarden', \n",
        "    'hacienda', \n",
        "    'snowtuxpeak',\n",
        "    'cornfield_crossing',\n",
        "    'scotland',\n",
        "    'cocoa_temple'\n",
        "          ]\n",
        "args_jt.tracks=tracks\n",
        "\n",
        "args_jt.trainset_dirs=[\n",
        "    'trainset_5000_samjt',\n",
        "    'trainset_5000_charlie',\n",
        "    # 'trainset_5000_jt'\n",
        "          ]\n",
        "args_jt.valset_dirs=[\n",
        "    'valset_5000_samjt',\n",
        "    'valset_5000_charlie',\n",
        "    # 'valset_5000_jt'\n",
        "          ]\n",
        "args_jt.device=\"cuda:3\"\n",
        "args_jt.learning_rate=8e-3\n",
        "args_jt.val_interval=1\n",
        "args_jt.num_epochs=5000\n",
        "args_jt.proportion=1\n",
        "\n",
        "args_jt.planner_name=\"adapted_planner_m3_jt3_v1.th\";\n",
        "args_jt.planner_type=AdaptedPlannerM3JT\n",
        "\n",
        "train_adaption_mod.train_adaption_jt(args_jt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KryqMZQwQErd",
        "outputId": "2250e90c-7c5c-4947-e624-9b815f88b5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Model =================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaptedPlannerM3JT(\n",
            "  (batch_norm): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (resnet): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            "  )\n",
            "  (adapters): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=1000, out_features=1024, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Linear(in_features=128, out_features=40, bias=True)\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=1000, out_features=1024, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Linear(in_features=128, out_features=40, bias=True)\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Linear(in_features=1000, out_features=1024, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Linear(in_features=128, out_features=40, bias=True)\n",
            "    )\n",
            "    (3): Sequential(\n",
            "      (0): Linear(in_features=1000, out_features=1024, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Linear(in_features=128, out_features=40, bias=True)\n",
            "    )\n",
            "    (4): Sequential(\n",
            "      (0): Linear(in_features=1000, out_features=1024, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Linear(in_features=128, out_features=40, bias=True)\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): Linear(in_features=1000, out_features=1024, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Linear(in_features=128, out_features=40, bias=True)\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): Linear(in_features=1000, out_features=1024, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=1024, out_features=2048, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Linear(in_features=512, out_features=256, bias=True)\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): Linear(in_features=256, out_features=128, bias=True)\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Linear(in_features=128, out_features=40, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "installing torch ...\n",
            "installing inspect ...\n",
            "loading data ...\n",
            "initial val loss = 0.13685305\n",
            "Begin Training =================================\n",
            "epoch 0   \t loss = 0.126169 val_loss= 0.12738787\n",
            "epoch 1   \t loss = 0.121151 val_loss= 0.12281839\n",
            "epoch 2   \t loss = 0.120666 val_loss= 0.12314445\n",
            "epoch 3   \t loss = 0.117323 val_loss= 0.11825351\n",
            "epoch 4   \t loss = 0.113909 val_loss= 0.11526453\n",
            "epoch 5   \t loss = 0.111660 val_loss= 0.113098636\n",
            "epoch 6   \t loss = 0.113608 val_loss= 0.11514784\n",
            "epoch 7   \t loss = 0.125271 val_loss= 0.13727222\n",
            "epoch 8   \t loss = 0.133056 val_loss= 0.13379212\n",
            "epoch 9   \t loss = 0.128694 val_loss= 0.12910196\n",
            "epoch 10  \t loss = 0.122949 val_loss= 0.120951205\n",
            "epoch 11  \t loss = 0.117020 val_loss= 0.117496446\n",
            "epoch 12  \t loss = 0.113843 val_loss= 0.11570235\n",
            "epoch 13  \t loss = 0.117371 val_loss= 0.11664\n",
            "epoch 14  \t loss = 0.112412 val_loss= 0.112907276\n",
            "epoch 15  \t loss = 0.109090 val_loss= 0.111704834\n",
            "epoch 16  \t loss = 0.113248 val_loss= 0.11349892\n",
            "epoch 17  \t loss = 0.108913 val_loss= 0.11116874\n",
            "epoch 18  \t loss = 0.113089 val_loss= 0.11349441\n",
            "epoch 19  \t loss = 0.108448 val_loss= 0.110490285\n",
            "epoch 20  \t loss = 0.107199 val_loss= 0.110229425\n",
            "epoch 21  \t loss = 0.107078 val_loss= 0.12347865\n",
            "epoch 22  \t loss = 0.115728 val_loss= 0.120426804\n",
            "epoch 23  \t loss = 0.113876 val_loss= 0.11342726\n",
            "epoch 24  \t loss = 0.109487 val_loss= 0.11117073\n",
            "epoch 25  \t loss = 0.107232 val_loss= 0.10988793\n",
            "epoch 26  \t loss = 0.107964 val_loss= 0.11140553\n",
            "epoch 27  \t loss = 0.107015 val_loss= 0.10926043\n",
            "epoch 28  \t loss = 0.104491 val_loss= 0.1084611\n",
            "epoch 29  \t loss = 0.103538 val_loss= 0.107792705\n",
            "epoch 30  \t loss = 0.102899 val_loss= 0.10740441\n",
            "epoch 31  \t loss = 0.102436 val_loss= 0.1075917\n",
            "epoch 32  \t loss = 0.102040 val_loss= 0.10676999\n",
            "epoch 33  \t loss = 0.101425 val_loss= 0.10715391\n",
            "epoch 34  \t loss = 0.101246 val_loss= 0.106936336\n",
            "epoch 35  \t loss = 0.100820 val_loss= 0.10655324\n",
            "epoch 36  \t loss = 0.100603 val_loss= 0.10598944\n",
            "epoch 37  \t loss = 0.100166 val_loss= 0.10722648\n",
            "epoch 38  \t loss = 0.099694 val_loss= 0.10609219\n",
            "epoch 39  \t loss = 0.099202 val_loss= 0.10554681\n",
            "epoch 40  \t loss = 0.099018 val_loss= 0.10546417\n",
            "epoch 41  \t loss = 0.098698 val_loss= 0.10512667\n",
            "epoch 42  \t loss = 0.098351 val_loss= 0.10455859\n",
            "epoch 43  \t loss = 0.098167 val_loss= 0.10549719\n",
            "epoch 44  \t loss = 0.097909 val_loss= 0.10542866\n",
            "epoch 45  \t loss = 0.097532 val_loss= 0.105488494\n",
            "epoch 46  \t loss = 0.097394 val_loss= 0.104764976\n",
            "epoch 47  \t loss = 0.097018 val_loss= 0.10488651\n",
            "epoch 48  \t loss = 0.097213 val_loss= 0.10426985\n",
            "epoch 49  \t loss = 0.096736 val_loss= 0.1043272\n",
            "epoch 50  \t loss = 0.096206 val_loss= 0.10439929\n",
            "epoch 51  \t loss = 0.096056 val_loss= 0.10367719\n",
            "epoch 52  \t loss = 0.095942 val_loss= 0.10402319\n",
            "epoch 53  \t loss = 0.095822 val_loss= 0.10453628\n",
            "epoch 54  \t loss = 0.095860 val_loss= 0.10388648\n",
            "epoch 55  \t loss = 0.095613 val_loss= 0.103547044\n",
            "epoch 56  \t loss = 0.095244 val_loss= 0.1038641\n",
            "epoch 57  \t loss = 0.095088 val_loss= 0.103650935\n",
            "epoch 58  \t loss = 0.094918 val_loss= 0.10316972\n",
            "epoch 59  \t loss = 0.094943 val_loss= 0.10388633\n",
            "epoch 60  \t loss = 0.095019 val_loss= 0.10320828\n",
            "epoch 61  \t loss = 0.094715 val_loss= 0.103360265\n",
            "epoch 62  \t loss = 0.094531 val_loss= 0.10333724\n",
            "epoch 63  \t loss = 0.094306 val_loss= 0.10305803\n",
            "epoch 64  \t loss = 0.094230 val_loss= 0.10363315\n",
            "epoch 65  \t loss = 0.094175 val_loss= 0.10313545\n",
            "epoch 66  \t loss = 0.094294 val_loss= 0.102912724\n",
            "epoch 67  \t loss = 0.093886 val_loss= 0.103015214\n",
            "epoch 68  \t loss = 0.093958 val_loss= 0.10284568\n",
            "epoch 69  \t loss = 0.093668 val_loss= 0.102782615\n",
            "epoch 70  \t loss = 0.093649 val_loss= 0.10336052\n",
            "epoch 71  \t loss = 0.093522 val_loss= 0.102866314\n",
            "epoch 72  \t loss = 0.093335 val_loss= 0.10287252\n",
            "epoch 73  \t loss = 0.093341 val_loss= 0.10296342\n",
            "epoch 74  \t loss = 0.093230 val_loss= 0.10302639\n",
            "epoch 75  \t loss = 0.093193 val_loss= 0.1025085\n",
            "epoch 76  \t loss = 0.093143 val_loss= 0.10264712\n",
            "epoch 77  \t loss = 0.093136 val_loss= 0.10278197\n",
            "epoch 78  \t loss = 0.093020 val_loss= 0.1026409\n",
            "epoch 79  \t loss = 0.092884 val_loss= 0.10274275\n",
            "epoch 80  \t loss = 0.092702 val_loss= 0.10230651\n",
            "epoch 81  \t loss = 0.092651 val_loss= 0.10272956\n",
            "epoch 82  \t loss = 0.092721 val_loss= 0.10266574\n",
            "epoch 83  \t loss = 0.092512 val_loss= 0.102923565\n",
            "epoch 84  \t loss = 0.092524 val_loss= 0.102372326\n",
            "epoch 85  \t loss = 0.092482 val_loss= 0.102593094\n",
            "epoch 86  \t loss = 0.092480 val_loss= 0.10313952\n",
            "epoch 87  \t loss = 0.092456 val_loss= 0.10245354\n",
            "epoch 88  \t loss = 0.092235 val_loss= 0.10212723\n",
            "epoch 89  \t loss = 0.092153 val_loss= 0.102089815\n",
            "epoch 90  \t loss = 0.092076 val_loss= 0.10273308\n",
            "epoch 91  \t loss = 0.092004 val_loss= 0.102242\n",
            "epoch 92  \t loss = 0.091818 val_loss= 0.102674685\n",
            "epoch 93  \t loss = 0.091586 val_loss= 0.10199362\n",
            "epoch 94  \t loss = 0.091558 val_loss= 0.101672255\n",
            "epoch 95  \t loss = 0.091482 val_loss= 0.101955\n",
            "epoch 96  \t loss = 0.091464 val_loss= 0.10210163\n",
            "epoch 97  \t loss = 0.091264 val_loss= 0.1025605\n",
            "epoch 98  \t loss = 0.091499 val_loss= 0.10259093\n",
            "epoch 99  \t loss = 0.091141 val_loss= 0.101766884\n",
            "epoch 100 \t loss = 0.090936 val_loss= 0.10193057\n",
            "epoch 101 \t loss = 0.090869 val_loss= 0.10179559\n",
            "epoch 102 \t loss = 0.090772 val_loss= 0.101571485\n",
            "epoch 103 \t loss = 0.090851 val_loss= 0.10203013\n",
            "epoch 104 \t loss = 0.090900 val_loss= 0.10205662\n",
            "epoch 105 \t loss = 0.090771 val_loss= 0.10211371\n",
            "epoch 106 \t loss = 0.090708 val_loss= 0.101688445\n",
            "epoch 107 \t loss = 0.090546 val_loss= 0.10202222\n",
            "epoch 108 \t loss = 0.090654 val_loss= 0.10188746\n",
            "epoch 109 \t loss = 0.090708 val_loss= 0.1015486\n",
            "epoch 110 \t loss = 0.090463 val_loss= 0.10142517\n",
            "epoch 111 \t loss = 0.090498 val_loss= 0.10180937\n",
            "epoch 112 \t loss = 0.090441 val_loss= 0.10144621\n",
            "epoch 113 \t loss = 0.090203 val_loss= 0.101392224\n",
            "epoch 114 \t loss = 0.090253 val_loss= 0.101473615\n",
            "epoch 115 \t loss = 0.090288 val_loss= 0.10143235\n",
            "epoch 116 \t loss = 0.090268 val_loss= 0.10148338\n",
            "epoch 117 \t loss = 0.090194 val_loss= 0.1015695\n",
            "epoch 118 \t loss = 0.090154 val_loss= 0.101858854\n",
            "epoch 119 \t loss = 0.090151 val_loss= 0.10198954\n",
            "epoch 120 \t loss = 0.090093 val_loss= 0.10146059\n",
            "epoch 121 \t loss = 0.090032 val_loss= 0.101488926\n",
            "epoch 122 \t loss = 0.089996 val_loss= 0.10129553\n",
            "epoch 123 \t loss = 0.089870 val_loss= 0.10183805\n",
            "epoch 124 \t loss = 0.089919 val_loss= 0.10160205\n",
            "epoch 125 \t loss = 0.090033 val_loss= 0.10142504\n",
            "epoch 126 \t loss = 0.090117 val_loss= 0.10175635\n",
            "epoch 127 \t loss = 0.089838 val_loss= 0.10132222\n",
            "epoch 128 \t loss = 0.089847 val_loss= 0.10150469\n",
            "epoch 129 \t loss = 0.090149 val_loss= 0.10164167\n",
            "epoch 130 \t loss = 0.090184 val_loss= 0.10152375\n",
            "epoch 131 \t loss = 0.089759 val_loss= 0.10132315\n",
            "epoch 132 \t loss = 0.089595 val_loss= 0.101368174\n",
            "epoch 133 \t loss = 0.089816 val_loss= 0.1014937\n",
            "epoch 134 \t loss = 0.089707 val_loss= 0.101413906\n",
            "epoch 135 \t loss = 0.089872 val_loss= 0.10145131\n",
            "epoch 136 \t loss = 0.089748 val_loss= 0.10168938\n",
            "epoch 137 \t loss = 0.089627 val_loss= 0.10135868\n",
            "epoch 138 \t loss = 0.089441 val_loss= 0.10199091\n",
            "epoch 139 \t loss = 0.089458 val_loss= 0.10144262\n",
            "epoch 140 \t loss = 0.089534 val_loss= 0.10137028\n",
            "epoch 141 \t loss = 0.089545 val_loss= 0.10132447\n",
            "epoch 142 \t loss = 0.089674 val_loss= 0.10127769\n",
            "epoch 143 \t loss = 0.089569 val_loss= 0.101163946\n",
            "epoch 144 \t loss = 0.089412 val_loss= 0.10120224\n",
            "epoch 145 \t loss = 0.089369 val_loss= 0.10106262\n",
            "epoch 146 \t loss = 0.089473 val_loss= 0.10149133\n",
            "epoch 147 \t loss = 0.089434 val_loss= 0.10101546\n",
            "epoch 148 \t loss = 0.089367 val_loss= 0.10148623\n",
            "epoch 149 \t loss = 0.089296 val_loss= 0.10145192\n",
            "epoch 150 \t loss = 0.089276 val_loss= 0.10130384\n",
            "epoch 151 \t loss = 0.089390 val_loss= 0.101527736\n",
            "epoch 152 \t loss = 0.089606 val_loss= 0.10137568\n",
            "epoch 153 \t loss = 0.089542 val_loss= 0.10144766\n",
            "epoch 154 \t loss = 0.089264 val_loss= 0.101269886\n",
            "epoch 155 \t loss = 0.089204 val_loss= 0.10126225\n",
            "epoch 156 \t loss = 0.089188 val_loss= 0.10127575\n",
            "epoch 157 \t loss = 0.089201 val_loss= 0.10125327\n",
            "epoch 158 \t loss = 0.089186 val_loss= 0.10107869\n",
            "epoch 159 \t loss = 0.089170 val_loss= 0.101469316\n",
            "epoch 160 \t loss = 0.089175 val_loss= 0.10133355\n",
            "epoch 161 \t loss = 0.089296 val_loss= 0.10138064\n",
            "epoch 162 \t loss = 0.089163 val_loss= 0.101426184\n",
            "epoch 163 \t loss = 0.089163 val_loss= 0.100947686\n",
            "epoch 164 \t loss = 0.089067 val_loss= 0.10134728\n",
            "epoch 165 \t loss = 0.089175 val_loss= 0.1009577\n",
            "epoch 166 \t loss = 0.089059 val_loss= 0.101087466\n",
            "epoch 167 \t loss = 0.089263 val_loss= 0.101066045\n",
            "epoch 168 \t loss = 0.089197 val_loss= 0.10164603\n",
            "epoch 169 \t loss = 0.089093 val_loss= 0.101188704\n",
            "epoch 170 \t loss = 0.088996 val_loss= 0.101308994\n",
            "epoch 171 \t loss = 0.088988 val_loss= 0.10157421\n",
            "epoch 172 \t loss = 0.089012 val_loss= 0.10138055\n",
            "epoch 173 \t loss = 0.089073 val_loss= 0.10184605\n",
            "epoch 174 \t loss = 0.089008 val_loss= 0.10111495\n",
            "epoch 175 \t loss = 0.088893 val_loss= 0.10097451\n",
            "epoch 176 \t loss = 0.088933 val_loss= 0.10095207\n",
            "epoch 177 \t loss = 0.088906 val_loss= 0.10114843\n",
            "epoch 178 \t loss = 0.088922 val_loss= 0.10107876\n",
            "epoch 179 \t loss = 0.089214 val_loss= 0.101425745\n",
            "epoch 180 \t loss = 0.089029 val_loss= 0.10106456\n",
            "epoch 181 \t loss = 0.088754 val_loss= 0.101017684\n",
            "epoch 182 \t loss = 0.088845 val_loss= 0.10086593\n",
            "epoch 183 \t loss = 0.088862 val_loss= 0.10112742\n",
            "epoch 184 \t loss = 0.088854 val_loss= 0.10104078\n",
            "epoch 185 \t loss = 0.088793 val_loss= 0.10093662\n",
            "epoch 186 \t loss = 0.088945 val_loss= 0.10102758\n",
            "epoch 187 \t loss = 0.088868 val_loss= 0.10113667\n",
            "epoch 188 \t loss = 0.088795 val_loss= 0.10154035\n",
            "epoch 189 \t loss = 0.088814 val_loss= 0.10104792\n",
            "epoch 190 \t loss = 0.088732 val_loss= 0.1012278\n",
            "epoch 191 \t loss = 0.088796 val_loss= 0.10102394\n",
            "epoch 192 \t loss = 0.088824 val_loss= 0.101008974\n",
            "epoch 193 \t loss = 0.088710 val_loss= 0.101038635\n",
            "epoch 194 \t loss = 0.089075 val_loss= 0.10167035\n",
            "epoch 195 \t loss = 0.088986 val_loss= 0.10076094\n",
            "epoch 196 \t loss = 0.088656 val_loss= 0.101078115\n",
            "epoch 197 \t loss = 0.088774 val_loss= 0.101035476\n",
            "epoch 198 \t loss = 0.088742 val_loss= 0.10082307\n",
            "epoch 199 \t loss = 0.088688 val_loss= 0.10105323\n",
            "epoch 200 \t loss = 0.088708 val_loss= 0.10098664\n",
            "epoch 201 \t loss = 0.088819 val_loss= 0.10105685\n",
            "epoch 202 \t loss = 0.088767 val_loss= 0.101123236\n",
            "epoch 203 \t loss = 0.088734 val_loss= 0.10087274\n",
            "epoch 204 \t loss = 0.088692 val_loss= 0.10097656\n",
            "epoch 205 \t loss = 0.088866 val_loss= 0.10077811\n",
            "epoch 206 \t loss = 0.088590 val_loss= 0.10072082\n",
            "epoch 207 \t loss = 0.088742 val_loss= 0.10132773\n",
            "epoch 208 \t loss = 0.088727 val_loss= 0.10088905\n",
            "epoch 209 \t loss = 0.088580 val_loss= 0.100787826\n",
            "epoch 210 \t loss = 0.088593 val_loss= 0.100799285\n",
            "epoch 211 \t loss = 0.088653 val_loss= 0.10081058\n",
            "epoch 212 \t loss = 0.088572 val_loss= 0.1009417\n",
            "epoch 213 \t loss = 0.088622 val_loss= 0.10112832\n",
            "epoch 214 \t loss = 0.088611 val_loss= 0.100973696\n",
            "epoch 215 \t loss = 0.088551 val_loss= 0.100841545\n",
            "epoch 216 \t loss = 0.088677 val_loss= 0.10056294\n",
            "epoch 217 \t loss = 0.088616 val_loss= 0.101031914\n",
            "epoch 218 \t loss = 0.088667 val_loss= 0.101067655\n",
            "epoch 219 \t loss = 0.088577 val_loss= 0.10082626\n",
            "epoch 220 \t loss = 0.088514 val_loss= 0.10083887\n",
            "epoch 221 \t loss = 0.088645 val_loss= 0.10165128\n",
            "epoch 222 \t loss = 0.088864 val_loss= 0.10078965\n",
            "epoch 223 \t loss = 0.088676 val_loss= 0.100732274\n",
            "epoch 224 \t loss = 0.088547 val_loss= 0.10072777\n",
            "epoch 225 \t loss = 0.088485 val_loss= 0.10085949\n",
            "epoch 226 \t loss = 0.088415 val_loss= 0.1006731\n",
            "epoch 227 \t loss = 0.088411 val_loss= 0.10045989\n",
            "epoch 228 \t loss = 0.088372 val_loss= 0.100692354\n",
            "epoch 229 \t loss = 0.088424 val_loss= 0.10093796\n",
            "epoch 230 \t loss = 0.088444 val_loss= 0.10074486\n",
            "epoch 231 \t loss = 0.088698 val_loss= 0.101235315\n",
            "epoch 232 \t loss = 0.088616 val_loss= 0.10069524\n",
            "epoch 233 \t loss = 0.088483 val_loss= 0.100604214\n",
            "epoch 234 \t loss = 0.088439 val_loss= 0.10086222\n",
            "epoch 235 \t loss = 0.088504 val_loss= 0.10111286\n",
            "epoch 236 \t loss = 0.088404 val_loss= 0.10105465\n",
            "epoch 237 \t loss = 0.088442 val_loss= 0.101012565\n",
            "epoch 238 \t loss = 0.088308 val_loss= 0.10072128\n",
            "epoch 239 \t loss = 0.088465 val_loss= 0.10088107\n",
            "epoch 240 \t loss = 0.088299 val_loss= 0.10069282\n",
            "epoch 241 \t loss = 0.088439 val_loss= 0.1009076\n",
            "epoch 242 \t loss = 0.088421 val_loss= 0.10097099\n",
            "epoch 243 \t loss = 0.088454 val_loss= 0.101329274\n",
            "epoch 244 \t loss = 0.088456 val_loss= 0.100906715\n",
            "epoch 245 \t loss = 0.088349 val_loss= 0.10081595\n",
            "epoch 246 \t loss = 0.088297 val_loss= 0.10054761\n",
            "epoch 247 \t loss = 0.088350 val_loss= 0.10100448\n",
            "epoch 248 \t loss = 0.088472 val_loss= 0.10075728\n",
            "epoch 249 \t loss = 0.088377 val_loss= 0.10081468\n",
            "epoch 250 \t loss = 0.088377 val_loss= 0.1009174\n",
            "epoch 251 \t loss = 0.088323 val_loss= 0.10089975\n",
            "epoch 252 \t loss = 0.088272 val_loss= 0.101241216\n",
            "epoch 253 \t loss = 0.088339 val_loss= 0.1007812\n",
            "epoch 254 \t loss = 0.088408 val_loss= 0.101014055\n",
            "epoch 255 \t loss = 0.088370 val_loss= 0.10079611\n",
            "epoch 256 \t loss = 0.088306 val_loss= 0.10078366\n",
            "epoch 257 \t loss = 0.088310 val_loss= 0.10063754\n",
            "epoch 258 \t loss = 0.088524 val_loss= 0.10125239\n",
            "epoch 259 \t loss = 0.088488 val_loss= 0.101273656\n",
            "epoch 260 \t loss = 0.088558 val_loss= 0.1012008\n",
            "epoch 261 \t loss = 0.088729 val_loss= 0.10079671\n",
            "epoch 262 \t loss = 0.088245 val_loss= 0.10090162\n",
            "epoch 263 \t loss = 0.088233 val_loss= 0.10114135\n",
            "epoch 264 \t loss = 0.088268 val_loss= 0.10075974\n",
            "epoch 265 \t loss = 0.088265 val_loss= 0.10072001\n",
            "epoch 266 \t loss = 0.088281 val_loss= 0.10091697\n",
            "epoch 267 \t loss = 0.088369 val_loss= 0.100838214\n",
            "epoch 268 \t loss = 0.088247 val_loss= 0.10076455\n",
            "epoch 269 \t loss = 0.088352 val_loss= 0.10082765\n",
            "epoch 270 \t loss = 0.088348 val_loss= 0.100900546\n",
            "epoch 271 \t loss = 0.088488 val_loss= 0.10075088\n",
            "epoch 272 \t loss = 0.088254 val_loss= 0.10082055\n",
            "epoch 273 \t loss = 0.088300 val_loss= 0.10060276\n",
            "epoch 274 \t loss = 0.088276 val_loss= 0.10060644\n",
            "epoch 275 \t loss = 0.088247 val_loss= 0.10086727\n",
            "epoch 276 \t loss = 0.088195 val_loss= 0.10065251\n",
            "epoch 277 \t loss = 0.088217 val_loss= 0.10067443\n",
            "epoch 278 \t loss = 0.088150 val_loss= 0.100565106\n",
            "epoch 279 \t loss = 0.088317 val_loss= 0.10097034\n",
            "epoch 280 \t loss = 0.088226 val_loss= 0.100551784\n",
            "epoch 281 \t loss = 0.088352 val_loss= 0.10076977\n",
            "epoch 282 \t loss = 0.088353 val_loss= 0.10097017\n",
            "epoch 283 \t loss = 0.088221 val_loss= 0.10063723\n",
            "epoch 284 \t loss = 0.088166 val_loss= 0.100639045\n",
            "epoch 285 \t loss = 0.088225 val_loss= 0.10069058\n",
            "epoch 286 \t loss = 0.088118 val_loss= 0.10087338\n",
            "epoch 287 \t loss = 0.088339 val_loss= 0.10053269\n",
            "epoch 288 \t loss = 0.088195 val_loss= 0.100608155\n",
            "epoch 289 \t loss = 0.088131 val_loss= 0.10058187\n",
            "epoch 290 \t loss = 0.088275 val_loss= 0.10065503\n",
            "epoch 291 \t loss = 0.088274 val_loss= 0.100750335\n",
            "epoch 292 \t loss = 0.088179 val_loss= 0.10051981\n",
            "epoch 293 \t loss = 0.088119 val_loss= 0.100590356\n",
            "epoch 294 \t loss = 0.088190 val_loss= 0.10105327\n",
            "epoch 295 \t loss = 0.088251 val_loss= 0.10060044\n",
            "epoch 296 \t loss = 0.088229 val_loss= 0.100770526\n",
            "epoch 297 \t loss = 0.088055 val_loss= 0.10093696\n",
            "epoch 298 \t loss = 0.088174 val_loss= 0.100615256\n",
            "epoch 299 \t loss = 0.088182 val_loss= 0.10083975\n",
            "epoch 300 \t loss = 0.088100 val_loss= 0.10054968\n",
            "epoch 301 \t loss = 0.088206 val_loss= 0.10103786\n",
            "epoch 302 \t loss = 0.088225 val_loss= 0.10091977\n",
            "epoch 303 \t loss = 0.088296 val_loss= 0.10100857\n",
            "epoch 304 \t loss = 0.088192 val_loss= 0.10090456\n",
            "epoch 305 \t loss = 0.088095 val_loss= 0.10050857\n",
            "epoch 306 \t loss = 0.088245 val_loss= 0.10061725\n",
            "epoch 307 \t loss = 0.088092 val_loss= 0.10101068\n",
            "epoch 308 \t loss = 0.088106 val_loss= 0.100795306\n",
            "epoch 309 \t loss = 0.088075 val_loss= 0.10058376\n",
            "epoch 310 \t loss = 0.087971 val_loss= 0.10058641\n",
            "epoch 311 \t loss = 0.088149 val_loss= 0.10097304\n",
            "epoch 312 \t loss = 0.088114 val_loss= 0.1009841\n",
            "epoch 313 \t loss = 0.088105 val_loss= 0.10088923\n",
            "epoch 314 \t loss = 0.088078 val_loss= 0.10089863\n",
            "epoch 315 \t loss = 0.088145 val_loss= 0.10044634\n",
            "epoch 316 \t loss = 0.088178 val_loss= 0.10092333\n",
            "epoch 317 \t loss = 0.088275 val_loss= 0.100808986\n",
            "epoch 318 \t loss = 0.088080 val_loss= 0.100596346\n",
            "epoch 319 \t loss = 0.087965 val_loss= 0.10070261\n",
            "epoch 320 \t loss = 0.088077 val_loss= 0.10104238\n",
            "epoch 321 \t loss = 0.088064 val_loss= 0.10043163\n",
            "epoch 322 \t loss = 0.088025 val_loss= 0.100706406\n",
            "epoch 323 \t loss = 0.088061 val_loss= 0.10102471\n",
            "epoch 324 \t loss = 0.088087 val_loss= 0.100794114\n",
            "epoch 325 \t loss = 0.088110 val_loss= 0.10080561\n",
            "epoch 326 \t loss = 0.088103 val_loss= 0.10105583\n",
            "epoch 327 \t loss = 0.087999 val_loss= 0.10074949\n",
            "epoch 328 \t loss = 0.088137 val_loss= 0.10121282\n",
            "epoch 329 \t loss = 0.088312 val_loss= 0.1010994\n",
            "epoch 330 \t loss = 0.088074 val_loss= 0.10087264\n",
            "epoch 331 \t loss = 0.088036 val_loss= 0.10065524\n",
            "epoch 332 \t loss = 0.087961 val_loss= 0.10065759\n",
            "epoch 333 \t loss = 0.087962 val_loss= 0.10104086\n",
            "epoch 334 \t loss = 0.087987 val_loss= 0.10086256\n",
            "epoch 335 \t loss = 0.088025 val_loss= 0.101014294\n",
            "epoch 336 \t loss = 0.088143 val_loss= 0.10069396\n",
            "epoch 337 \t loss = 0.088006 val_loss= 0.1005851\n",
            "epoch 338 \t loss = 0.087904 val_loss= 0.10070604\n",
            "epoch 339 \t loss = 0.087977 val_loss= 0.10074826\n",
            "epoch 340 \t loss = 0.088026 val_loss= 0.10087522\n",
            "epoch 341 \t loss = 0.088077 val_loss= 0.10078542\n",
            "epoch 342 \t loss = 0.088054 val_loss= 0.10060614\n",
            "epoch 343 \t loss = 0.088053 val_loss= 0.101376094\n",
            "epoch 344 \t loss = 0.088102 val_loss= 0.10059555\n",
            "epoch 345 \t loss = 0.087950 val_loss= 0.10068056\n",
            "epoch 346 \t loss = 0.088157 val_loss= 0.10051778\n",
            "epoch 347 \t loss = 0.087988 val_loss= 0.10064306\n",
            "epoch 348 \t loss = 0.087910 val_loss= 0.100868225\n",
            "epoch 349 \t loss = 0.088062 val_loss= 0.10084714\n",
            "epoch 350 \t loss = 0.088036 val_loss= 0.10125633\n",
            "epoch 351 \t loss = 0.087918 val_loss= 0.10080848\n",
            "epoch 352 \t loss = 0.088062 val_loss= 0.100769415\n",
            "epoch 353 \t loss = 0.087944 val_loss= 0.10055089\n",
            "epoch 354 \t loss = 0.088017 val_loss= 0.10057501\n",
            "epoch 355 \t loss = 0.087915 val_loss= 0.10064291\n",
            "epoch 356 \t loss = 0.087976 val_loss= 0.10090209\n",
            "epoch 357 \t loss = 0.087989 val_loss= 0.1005954\n",
            "epoch 358 \t loss = 0.087914 val_loss= 0.100455195\n",
            "epoch 359 \t loss = 0.087942 val_loss= 0.10051153\n",
            "epoch 360 \t loss = 0.087932 val_loss= 0.10080541\n",
            "epoch 361 \t loss = 0.087848 val_loss= 0.10061729\n",
            "epoch 362 \t loss = 0.087939 val_loss= 0.10058202\n",
            "epoch 363 \t loss = 0.087986 val_loss= 0.10074669\n",
            "epoch 364 \t loss = 0.088002 val_loss= 0.10076087\n",
            "epoch 365 \t loss = 0.088056 val_loss= 0.10096112\n",
            "epoch 366 \t loss = 0.087982 val_loss= 0.100449674\n",
            "epoch 367 \t loss = 0.087900 val_loss= 0.10062629\n",
            "epoch 368 \t loss = 0.087985 val_loss= 0.10087985\n",
            "epoch 369 \t loss = 0.087959 val_loss= 0.10051319\n",
            "epoch 370 \t loss = 0.087940 val_loss= 0.10057844\n",
            "epoch 371 \t loss = 0.087996 val_loss= 0.10081849\n",
            "epoch 372 \t loss = 0.087938 val_loss= 0.10078191\n",
            "epoch 373 \t loss = 0.087873 val_loss= 0.10091603\n",
            "epoch 374 \t loss = 0.087914 val_loss= 0.10089002\n",
            "epoch 375 \t loss = 0.087878 val_loss= 0.10041152\n",
            "epoch 376 \t loss = 0.087899 val_loss= 0.10057194\n",
            "epoch 377 \t loss = 0.087919 val_loss= 0.10086114\n",
            "epoch 378 \t loss = 0.088004 val_loss= 0.100572206\n",
            "epoch 379 \t loss = 0.087844 val_loss= 0.10120962\n",
            "epoch 380 \t loss = 0.088016 val_loss= 0.100983836\n",
            "epoch 381 \t loss = 0.087981 val_loss= 0.10110577\n",
            "epoch 382 \t loss = 0.087866 val_loss= 0.10048289\n",
            "epoch 383 \t loss = 0.087905 val_loss= 0.10076856\n",
            "epoch 384 \t loss = 0.087987 val_loss= 0.10057354\n",
            "epoch 385 \t loss = 0.087870 val_loss= 0.1006086\n",
            "epoch 386 \t loss = 0.087965 val_loss= 0.10073169\n",
            "epoch 387 \t loss = 0.087853 val_loss= 0.100864574\n",
            "epoch 388 \t loss = 0.087860 val_loss= 0.100668944\n",
            "epoch 389 \t loss = 0.087786 val_loss= 0.10098549\n",
            "epoch 390 \t loss = 0.087936 val_loss= 0.10048771\n",
            "epoch 391 \t loss = 0.087809 val_loss= 0.10079789\n",
            "epoch 392 \t loss = 0.087928 val_loss= 0.100977816\n",
            "epoch 393 \t loss = 0.087967 val_loss= 0.1007656\n",
            "epoch 394 \t loss = 0.087900 val_loss= 0.10087187\n",
            "epoch 395 \t loss = 0.087969 val_loss= 0.100832045\n",
            "epoch 396 \t loss = 0.087888 val_loss= 0.10072202\n",
            "epoch 397 \t loss = 0.087878 val_loss= 0.10079639\n",
            "epoch 398 \t loss = 0.087854 val_loss= 0.100701205\n",
            "epoch 399 \t loss = 0.087799 val_loss= 0.10085874\n",
            "epoch 400 \t loss = 0.087850 val_loss= 0.101010665\n",
            "epoch 401 \t loss = 0.087854 val_loss= 0.10129213\n",
            "epoch 402 \t loss = 0.088078 val_loss= 0.10064113\n",
            "epoch 403 \t loss = 0.087866 val_loss= 0.10074713\n",
            "epoch 404 \t loss = 0.087788 val_loss= 0.10059548\n",
            "epoch 405 \t loss = 0.087852 val_loss= 0.10072473\n",
            "epoch 406 \t loss = 0.087976 val_loss= 0.100834824\n",
            "epoch 407 \t loss = 0.087938 val_loss= 0.10076192\n",
            "epoch 408 \t loss = 0.087841 val_loss= 0.100466646\n",
            "epoch 409 \t loss = 0.087842 val_loss= 0.1009425\n",
            "epoch 410 \t loss = 0.087781 val_loss= 0.10058977\n",
            "epoch 411 \t loss = 0.087856 val_loss= 0.10082689\n",
            "epoch 412 \t loss = 0.087898 val_loss= 0.10038299\n",
            "epoch 413 \t loss = 0.087800 val_loss= 0.100613505\n",
            "epoch 414 \t loss = 0.087738 val_loss= 0.10060758\n",
            "epoch 415 \t loss = 0.087797 val_loss= 0.1007026\n",
            "epoch 416 \t loss = 0.087903 val_loss= 0.10090126\n",
            "epoch 417 \t loss = 0.087934 val_loss= 0.10072887\n",
            "epoch 418 \t loss = 0.087843 val_loss= 0.101008385\n",
            "epoch 419 \t loss = 0.087800 val_loss= 0.10090971\n",
            "epoch 420 \t loss = 0.087808 val_loss= 0.10068452\n",
            "epoch 421 \t loss = 0.087749 val_loss= 0.10069497\n",
            "epoch 422 \t loss = 0.087746 val_loss= 0.100821\n",
            "epoch 423 \t loss = 0.087724 val_loss= 0.100823924\n",
            "epoch 424 \t loss = 0.087773 val_loss= 0.10054005\n",
            "epoch 425 \t loss = 0.087796 val_loss= 0.100630656\n",
            "epoch 426 \t loss = 0.087864 val_loss= 0.10085171\n",
            "epoch 427 \t loss = 0.087760 val_loss= 0.1005869\n",
            "epoch 428 \t loss = 0.087926 val_loss= 0.10098867\n",
            "epoch 429 \t loss = 0.087781 val_loss= 0.10048807\n",
            "epoch 430 \t loss = 0.087769 val_loss= 0.10045457\n",
            "epoch 431 \t loss = 0.087754 val_loss= 0.1004232\n",
            "epoch 432 \t loss = 0.087772 val_loss= 0.10073608\n",
            "epoch 433 \t loss = 0.087812 val_loss= 0.100622915\n",
            "epoch 434 \t loss = 0.087889 val_loss= 0.10083791\n",
            "epoch 435 \t loss = 0.087860 val_loss= 0.10082108\n",
            "epoch 436 \t loss = 0.087812 val_loss= 0.10093424\n",
            "epoch 437 \t loss = 0.087795 val_loss= 0.100721054\n",
            "epoch 438 \t loss = 0.087728 val_loss= 0.10057666\n",
            "epoch 439 \t loss = 0.087737 val_loss= 0.100537166\n",
            "epoch 440 \t loss = 0.087772 val_loss= 0.10070578\n",
            "epoch 441 \t loss = 0.087741 val_loss= 0.10058244\n",
            "epoch 442 \t loss = 0.087777 val_loss= 0.10083087\n",
            "epoch 443 \t loss = 0.087810 val_loss= 0.100597925\n",
            "epoch 444 \t loss = 0.087822 val_loss= 0.10056675\n",
            "epoch 445 \t loss = 0.087761 val_loss= 0.100371614\n",
            "epoch 446 \t loss = 0.087777 val_loss= 0.10064164\n",
            "epoch 447 \t loss = 0.087847 val_loss= 0.10065939\n",
            "epoch 448 \t loss = 0.087746 val_loss= 0.10063897\n",
            "epoch 449 \t loss = 0.087762 val_loss= 0.10063965\n",
            "epoch 450 \t loss = 0.087801 val_loss= 0.10059403\n",
            "epoch 451 \t loss = 0.087710 val_loss= 0.10032906\n",
            "epoch 452 \t loss = 0.087643 val_loss= 0.10057595\n",
            "epoch 453 \t loss = 0.087743 val_loss= 0.10044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AdaptedPlannerM2JT"
      ],
      "metadata": {
        "id": "QrA4oz2g3jCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Recognizer(PlannerResJT):\n",
        "  def forward(self, image_batch):# [batch_size,channel_size=3,height=96,width=128]\n",
        "    \"\"\"\n",
        "    Your code here\n",
        "    Predict the aim point in image coordinate, given the supertuxkart image\n",
        "    @img: (B,3,96,128)\n",
        "    return (B,2) \n",
        "    \"\"\"\n",
        "    \n",
        "    x = self.batch_norm(image_batch)\n",
        "    x = self.resnet(x)#[batch_size, 1, 6, 8]\n",
        "    return x \n",
        "\n",
        "\n",
        "\n",
        "recognizer=train_module_jt.load_planner_jt(\"planner_res_jt_v2.th\", Recognizer)\n",
        "recognizer.eval()\n",
        "\n",
        "classifier=train_module_jt.load_planner_jt(\"classifier_res_jt1_v3.th\", ClassifierJT)\n",
        "classifier.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AdaptedPlannerM2JT(torch.nn.Module):\n",
        "  def __init__(self,device=\"cuda:0\"):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "\n",
        "    self.adapters=ModuleList()\n",
        "    for track_code in range(global_variables.NUM_TRACKS):\n",
        "      \n",
        "      ll5=[]\n",
        "      ll=ll5\n",
        "      ll.append(BatchNorm2d(num_features=1))\n",
        "      ll.append(Conv2d(in_channels=1,out_channels=32,kernel_size=3,stride=1,padding=1))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "      ll.append(Conv2d(in_channels=32,out_channels=32,kernel_size=3,stride=1,padding=1))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "\n",
        "      # ll.append(MaxPool2d(kernel_size=2,stride=2))\n",
        "\n",
        "      ll.append(BatchNorm2d(num_features=32))\n",
        "      ll.append(Conv2d(in_channels=32,out_channels=64,kernel_size=5,stride=1,padding=2))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "      ll.append(Conv2d(in_channels=64,out_channels=64,kernel_size=5,stride=1,padding=2))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "      ll.append(Conv2d(in_channels=64,out_channels=64,kernel_size=5,stride=1,padding=2))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "\n",
        "      # ll.append(MaxPool2d(kernel_size=2,stride=2))\n",
        "\n",
        "      ll.append(BatchNorm2d(num_features=64))\n",
        "      ll.append(Conv2d(in_channels=64,out_channels=64,kernel_size=5,stride=1,padding=2))\n",
        "      ll.append(ReLU(inplace=True))\n",
        "\n",
        "      ll.append(Conv2d(in_channels=64,out_channels=1,kernel_size=1))\n",
        "\n",
        "\n",
        "      adapter=torch.nn.Sequential(*ll5)\n",
        "      self.adapters.append(adapter)\n",
        "    \n",
        "    \n",
        "  def forward(self, image_batch, code_batch=None,device=\"cuda:0\"):# [batch_size,channel_size=3,height=96,width=128]\n",
        "    \"\"\"\n",
        "    Your code here\n",
        "    Predict the aim point in image coordinate, given the supertuxkart image\n",
        "    @img: (B,3,96,128)\n",
        "    return (B,2) \n",
        "    \"\"\"\n",
        "\n",
        "    if code_batch is None:\n",
        "      classifier.to(device)\n",
        "      classifier.eval()\n",
        "      code_batch=classifier(image_batch).argmax(1)\n",
        "\n",
        "\n",
        "    batch_size=len(image_batch)\n",
        "    num_tracks=global_variables.NUM_TRACKS\n",
        "    width=40\n",
        "    height=25\n",
        "    \n",
        "\n",
        "\n",
        "    indices_list=[[] for i in range(num_tracks)]\n",
        "    for index in range(batch_size):\n",
        "      indices_list[code_batch[index].item()].append(index) \n",
        "\n",
        "\n",
        "    recognizer.to(device)\n",
        "    recognizer.eval()\n",
        "    map_batch=recognizer(image_batch).reshape(-1,1,height,width)\n",
        "\n",
        "\n",
        "\n",
        "    mini_map_batches=[]\n",
        "    for i in range(num_tracks):\n",
        "      mini_map_batches.append(map_batch.index_select(0,torch.tensor(indices_list[i], dtype=torch.int32).to(device)))\n",
        "    \n",
        "\n",
        "    weights_batch=[1]*batch_size\n",
        "    for i in range(num_tracks):\n",
        "\n",
        "      mini_map_batch=mini_map_batches[i]\n",
        "      mini_map_batch.to(device)\n",
        "\n",
        "      if len(mini_map_batch)==0:\n",
        "        continue\n",
        "\n",
        "      z=self.adapters[i](mini_map_batch)\n",
        "\n",
        "      for j in range(len(mini_map_batch)):\n",
        "        weights_batch[indices_list[i][j]]=z[j]\n",
        "    \n",
        "\n",
        "\n",
        "    # weights_batch=F.softmax(weights_batch, dim=1)\n",
        "    weights_batch=torch.stack(weights_batch).to(device) # batchsize, 1, 40\n",
        "\n",
        "\n",
        "    return spatial_argmax_jt(weights_batch[:,0])\n",
        "\n",
        "\n",
        "# adapted_planner_m2=AdaptedPlannerM2JT(device=\"cpu\")\n",
        "# print(adapted_planner_m2)\n",
        "# output=adapted_planner_m2(image_batch.to(\"cpu\"),code_batch=code_batch.to(\"cpu\"),device=\"cpu\")\n",
        "# print(output)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycyIgsDq3nFG",
        "outputId": "7d4bed9f-dd16-4152-cac6-306b029ab27f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AdaptedPlannerJT"
      ],
      "metadata": {
        "id": "6WSXWLDbfQA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "classifier=train_module_jt.load_planner_jt(\"classifier_res_jt1_v3.th\", ClassifierJT)\n",
        "classifier.eval()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class AdaptedPlannerJT(torch.nn.Module):\n",
        "  def __init__(self,device=\"cuda:0\"):\n",
        "\n",
        "    super().__init__()\n",
        "    \n",
        "    if True:\n",
        "      self.pool=torch.nn.AvgPool2d(kernel_size=3, stride=3,padding=1)\n",
        "      batch_norms=[]\n",
        "      adapters=[]\n",
        "      for track_code in range(global_variables.NUM_TRACKS):\n",
        "        batch_norms.append(BatchNorm2d(num_features=3).to(device))\n",
        "        adapters.append(torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False).to(device))\n",
        "      self.batch_norms=ModuleList(batch_norms)\n",
        "      self.adapters=ModuleList(adapters)\n",
        "\n",
        "\n",
        "    self.main_batch_norm=BatchNorm2d(num_features=3).to(device)\n",
        "    self.resnet=torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=False).to(device)\n",
        "    \n",
        "\n",
        "  def forward(self, image_batch, code_batch=None,device=\"cuda:0\"):# [batch_size,channel_size=3,height=96,width=128]\n",
        "    \"\"\"\n",
        "    Your code here\n",
        "    Predict the aim point in image coordinate, given the supertuxkart image\n",
        "    @img: (B,3,96,128)\n",
        "    return (B,2) \n",
        "    \"\"\"\n",
        "\n",
        "    if True:\n",
        "\n",
        "      if code_batch is None:\n",
        "        classifier.to(device)\n",
        "        classifier.eval()\n",
        "        code_batch=classifier(image_batch).argmax(1)\n",
        "\n",
        "      batch_size=len(image_batch)\n",
        "      num_tracks=global_variables.NUM_TRACKS\n",
        "\n",
        "      indices_list=[[] for i in range(num_tracks)]\n",
        "      for index in range(batch_size):\n",
        "        indices_list[code_batch[index].item()].append(index) \n",
        "  \n",
        "\n",
        "      mini_batches=[]\n",
        "      for i in range(num_tracks):\n",
        "\n",
        "        mini_batches.append(image_batch.index_select(0,torch.tensor(indices_list[i], dtype=torch.int32).to(device)))\n",
        "      \n",
        "      adapted_batch=torch.zeros(batch_size,1000).to(device)\n",
        "\n",
        "      for i in range(num_tracks):\n",
        "\n",
        "        mini_batch=mini_batches[i]\n",
        "        mini_batch.to(device)\n",
        "\n",
        "        if len(mini_batch)==0:\n",
        "          continue\n",
        "        \n",
        "        z=self.pool(mini_batch)\n",
        "        z=self.batch_norms[i](z)\n",
        "        z=self.adapters[i](z)\n",
        "        for j in range(len(mini_batch)):\n",
        "          adapted_batch[indices_list[i][j]]=z[j]\n",
        "\n",
        "      # adapted_batch=F.softmax(F.softmax(adapted_batch, dim=1)*1000,dim=1)*1000\n",
        "      adapted_batch=F.softmax(F.softmax(adapted_batch, dim=1)*1000,dim=1)*1000\n",
        "\n",
        "      adapted_batch.to(device)\n",
        "      # print(\"adapted_batch\",adapted_batch)\n",
        "      # print(adapted_batch.sum(1))\n",
        "\n",
        "    x = self.main_batch_norm(image_batch)\n",
        "    x = self.resnet(x)\n",
        "    x.to(device)\n",
        "\n",
        "\n",
        "    x=x.mul(adapted_batch) #jt5 adapted\n",
        "\n",
        "    x=x.reshape(-1,25,40)\n",
        "\n",
        "\n",
        "    return spatial_argmax_jt(x) #輸入是[batch_size,height=6,width=8],輸出是[batch_size,2]\n",
        "\n",
        "\n",
        "\n",
        "adapted_planner=AdaptedPlannerJT(device=\"cpu\")\n",
        "output=adapted_planner(image_batch.to(\"cpu\"),code_batch=code_batch.to(\"cpu\"),device=\"cpu\")\n",
        "print(output)\n",
        "# print(code_batch.index_select(0,torch.tensor([0,1,2])))"
      ],
      "metadata": {
        "id": "XFXxfUtmfSBp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afbebf1a-a528-4d95-e676-b27d67dd95b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n",
            "Using cache found in /home/phuang/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2308, -0.2500],\n",
            "        [ 0.2248,  0.0163]], grad_fn=<StackBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7UEAkKVD3hjC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ez0bQ70Z8yir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VhexKUzvUVkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test planner"
      ],
      "metadata": {
        "id": "j2BMRKcmUXc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_planner_jt(pytux,tracks, planner_name,planner_type, control_func,verbose):\n",
        "    # Load model\n",
        "    planner = train_module_jt.load_planner_jt(planner_name,planner_type).eval()\n",
        "    print(planner)\n",
        "    planner.to(\"cuda\")\n",
        "\n",
        "    sum=0\n",
        "    for t in tracks:\n",
        "        steps, how_far = pytux.rollout(t, control_func, planner=planner, max_frames=1000, verbose=verbose)\n",
        "        sum=sum+steps\n",
        "        print(t,steps, how_far)\n",
        "    print(\"total\",sum)\n",
        "\n",
        "\n",
        "tracks = [\n",
        "    'lighthouse', \n",
        "    'zengarden', \n",
        "    'hacienda', \n",
        "    'snowtuxpeak',\n",
        "    'cornfield_crossing',\n",
        "    'scotland',\n",
        "    'cocoa_temple'\n",
        "          ]   \n",
        "\n",
        "test_planner_jt(pytux_jt,\n",
        "                tracks,\n",
        "                planner_name=\"adapted_planner_jt1_v1.th\",\n",
        "                planner_type=AdaptedPlannerJT,\n",
        "                control_func=control_func_module_team.control_func_samjt,\n",
        "                verbose=True)\n"
      ],
      "metadata": {
        "id": "EM1b0LV0UYxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_demo_images_codes_batch():\n",
        "\n",
        "    dataset_path=\"dataset_base/valset_5000_samjt/zengarden\"\n",
        "    transform=dense_transforms.ToTensor()\n",
        "\n",
        "    data = []\n",
        "    NUM=2\n",
        "    counter=NUM\n",
        "    from PIL import Image\n",
        "    from glob import glob\n",
        "    from os import path\n",
        "\n",
        "    for f in glob(path.join(dataset_path, '*.csv')):\n",
        "\n",
        "      i = Image.open(f.replace('.csv', '.png'))\n",
        "      i.load()\n",
        "      data.append((i, np.loadtxt(f, dtype=np.float32, delimiter=',')))\n",
        "\n",
        "      counter-=1\n",
        "      if counter==0:\n",
        "        break\n",
        "\n",
        "    image_list=[]\n",
        "    code_list=[0]*NUM\n",
        "    for idx in range(NUM):\n",
        "      sample = data[idx]\n",
        "      sample = transform(*sample)\n",
        "      image, label= sample\n",
        "      image_list.append(image)\n",
        "\n",
        "    image_batch=torch.stack(image_list)\n",
        "    code_batch=torch.tensor(code_list,dtype=torch.int)\n",
        "    return image_batch, code_batch\n",
        "\n"
      ],
      "metadata": {
        "id": "uFlRtO-Rocf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch, code_batch=get_demo_images_codes_batch()\n",
        "print(image_batch.shape)\n",
        "print(code_batch.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOkPJji7qICN",
        "outputId": "715caa3b-24eb-4534-9530-168b77175c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 96, 128])\n",
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQtae9ymrVDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_batch_c=image_batch.clone()\n",
        "\n",
        "classifier_jt=train_module_jt.load_planner_jt(\"classifier_res_jt1_v3.th\", ClassifierJT)\n",
        "classifier_jt.eval()\n",
        "print(classifier_jt(image_batch).argmax(1))\n",
        "\n",
        "print(torch.all(torch.eq(image_batch, image_batch_c)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "kygy5AJ-qUIY",
        "outputId": "2ea04c0d-75dd-4188-a8e2-40735da04723"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_2374792/419962920.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_batch_c\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclassifier_jt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_module_jt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_planner_jt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classifier_res_jt1_v3.th\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassifierJT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclassifier_jt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier_jt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_batch' is not defined"
          ]
        }
      ]
    }
  ]
}